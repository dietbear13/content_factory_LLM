import json
import os
import logging

from langchain.chat_models import ChatOpenAI
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langchain.chains import LLMChain


class ContentGenerator:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –≤ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ.
    –£–ø–æ—Ä –Ω–∞ —Ñ–∞–∫—Ç—ã, –∏–∑–±–µ–≥–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–æ–≤, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
    """

    def __init__(self, config_path=None):
        if config_path is None:
            script_dir = os.path.dirname(os.path.realpath(__file__))
            config_path = os.path.join(script_dir, "configs", "content_config.json")

        with open(config_path, "r", encoding="utf-8") as f:
            self.config = json.load(f)

        self.model_name = self.config.get("model_name", "gpt-4")
        self.temperature = self.config.get("temperature", 0.3)
        self.top_p = self.config.get("top_p", 1.0)
        self.presence_penalty = self.config.get("presence_penalty", 0.0)
        self.frequency_penalty = self.config.get("frequency_penalty", 0.0)

        self.default_length = self.config.get("default_length", 400)
        self.style = self.config.get("style", "–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π")
        self.tone = self.config.get("tone", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π")

        self.criteria = self.config.get("criteria", {})
        self.use_citations = self.config.get("use_citations", False)
        self.citations_style = self.config.get("citations_style", "APA")

        self.llm = ChatOpenAI(
            model_name=self.model_name,
            temperature=self.temperature,
            top_p=self.top_p,
            presence_penalty=self.presence_penalty,
            frequency_penalty=self.frequency_penalty
        )

        self.system_message_template = """
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –∞–≤—Ç–æ—Ä, —Å–æ–∑–¥–∞—é—â–∏–π –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–°—Ç–∏–ª—å: {style}. –¢–æ–Ω: {tone}.
–°–ª–µ–¥—É–π –ø—Ä–∏–Ω—Ü–∏–ø–∞–º ¬´–ü–∏—à–∏, —Å–æ–∫—Ä–∞—â–∞–π¬ª.

üìå –ü–∏—à–∏ —Ç–æ–ª—å–∫–æ –ø–æ —Å—É—â–µ—Å—Ç–≤—É:
- –ë–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π, –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏.
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–ª–∏—à–µ –∏ —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã.
- –ù–µ –ø–æ–≤—Ç–æ—Ä—è–π—Å—è.

üìå –°—Ç—Ä—É–∫—Ç—É—Ä–∞:
- 3‚Äì4 –∞–±–∑–∞—Ü–∞ –ø–æ 100‚Äì150 —Å–ª–æ–≤.
- –ö–∞–∂–¥—ã–π –∞–±–∑–∞—Ü –¥–æ–ª–∂–µ–Ω —Ä–∞—Å–∫—Ä—ã–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π –∞—Å–ø–µ–∫—Ç –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞.

üìå –ö—Ä–∏—Ç–µ—Ä–∏–∏:
{criteria_block}

üìå –†–∞–±–æ—Ç–∞ —Å —Ñ–∞–∫—Ç–∞–º–∏:
- –ï—Å–ª–∏ {use_citations} = true ‚Äî –≤—Å—Ç–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏ –≤ —Å—Ç–∏–ª–µ {citations_style}.
- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞ ‚Äî —Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ.
- –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ‚Äî –¥–∞–π –æ–±–∑–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ (fallback).
"""

        self.human_message_template = """
–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (3‚Äì4 –∞–±–∑–∞—Ü–∞) –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É:
"{headline}"

–í –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –æ–±—â–µ–π —Ç–µ–º—ã:
"{global_theme}"

–û–±—ä—ë–º: ~{default_length} —Å–ª–æ–≤.
"""

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
        criteria_lines = []
        if self.criteria.get("use_examples"):
            criteria_lines.append("- –ü—Ä–∏–≤–æ–¥–∏ –ø—Ä–∏–º–µ—Ä—ã.")
        if self.criteria.get("use_numerical_data"):
            criteria_lines.append("- –ò—Å–ø–æ–ª—å–∑—É–π —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        if self.criteria.get("min_paragraphs") or self.criteria.get("max_paragraphs"):
            criteria_lines.append(f"- –û—Ç {self.criteria.get('min_paragraphs', 2)} –¥–æ {self.criteria.get('max_paragraphs', 4)} –∞–±–∑–∞—Ü–µ–≤.")

        self.criteria_block = "\n".join(criteria_lines) if criteria_lines else "- –ù–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤."

        self.chat_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(self.system_message_template),
            HumanMessagePromptTemplate.from_template(self.human_message_template)
        ])

    def run(self, headline: str, global_theme: str) -> str:
        logging.info(f"[ContentGenerator] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞: ¬´{headline}¬ª (–≤ —Ç–µ–º–µ: {global_theme})")

        chain_input = {
            "style": self.style,
            "tone": self.tone,
            "use_citations": str(self.use_citations).lower(),
            "citations_style": self.citations_style,
            "headline": headline,
            "global_theme": global_theme,
            "default_length": self.default_length,
            "criteria_block": self.criteria_block
        }

        chain = LLMChain(llm=self.llm, prompt=self.chat_prompt)
        return chain.run(chain_input)
